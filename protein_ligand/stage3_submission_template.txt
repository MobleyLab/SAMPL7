# Results for PHIP2 library selection
#
# This file will be automatically parsed.  It must contain the following eight elements:
# predictions, participant name, participant organization, name of method, software listing, method, method category, and ranked.
# These elements must be provided in the order shown.
# The file name must begin with the letters "PHIP2" and then be followed by an underscore or dash.
#
# FILE FORMAT: All comment lines in this file (which begin with #) will be ignored.
# Please use only UTF-8 characters in the non-comment fields. If your information (e.g. your name, etc.)
# contains a non-UTF-8 character, you may note it in comments near that entry.


# PREDICTIONS SECTION
#
# The data in each prediction line should be structured as follows:
# Rank (1 through N, with N >= 100; and 1 being the top predicted compound),
# Compound ID (eg "REAL:Z1545197621"; use an ID from REAL or MOLPORT but not both),
# SMILES string, 
# confidence that binding is improved (1-10, with 10 being most confident)
#
# Note that you will likely want to justify your specific predictions/choices in your Method section, as our
# evaluators will read there to determine why you have made the choices you did.
#
# As per challenge rules, depending on participation, we may be considering only your top 10 ranked compounds, and
# selection for screening will depend on whether the compounds seem reasonable and on your justification for
# your choices. 
#
# The list of predictions must begin with the "Predictions:" keyword, as illustrated here.
Predictions:
1, REAL:Z1545197621, Fc1ccccc1NCc1cn[nH]c1, 3
2, REAL:PV-001924679156, CCCn1cc(CNc2ccccc2F)c(C)n1, 2
3, REAL:Z3075424149, O=C(C1CC1F)N1CCN(c2ccc(F)cc2)CC1, 2


# PARTICIPANT INFORMATION SECTION
#
# Please list your name, using only UTF-8 characters as described above. The "Participant name:" entry is required.
Participant name:
David Mobley
#
# Please list your organization/affiliation, using only UTF-8 characters as described above.
Participant organization:
University of California, Irvine


# METHOD NAME SECTION
#
# Please provide a brief (40 character limit) informal yet informative name of the method used.
# Following is sample text; please edit to your taste.
# The "Name:" keyword is required, as shown here.
# 40 character limit.
Name:
OEDocking-template


# SOFTWARE SECTION
#
# All major software packages used and their versions.
# Please use a new line for each software.
# Following is sample text; please edit to your taste.
# The "Software:" keyword is required.
Software:
OpenEye docking toolkit v1.1


# METHOD CATEGORY SECTION
#
# State which of the method category labels describe your prediction the best: `Docking`, `Ligand-based`, `MD`, `ML`, `Other`, `Null`.
# If your method takes advantage of multiple approaches please report more than one category label, separated by comma.
# `Docking` category refers to structure-based virtual screening methods that model the structure of the receptor binding pocket and pose of the ligand followed by an scoring the goodness of the fit .
# `Ligand-based` methods are virtual screening methods that do not rely on protein structure such as pharmacophore modeling, ligand shape-based, 2D or 3D structural similarity based methods.
# `MD` methods utilize molecular dynamics simulations based on molecular mechanics including free energy calculations.
# `ML` category includes machine learning, QSPR approaches, and all prediction methods trained on empirical knowledge.
# `Null` predictions employ a model which is not expected to produce useful predictions, however,  can provide a simple comparison point for more sophisticated methods, as ideally, good methods should outperform the null model.
# If these categories do not match your method, report as “Other”.
# If you choose the `Other` category, please explain your decision in the beginning of Method Description section.
# The `Category:` keyword is required.
Category:
Docking, MD


# RANKING INFORMATION SECTION
#
# All submissions must either be ranked or non-ranked.
# Only one ranked submission per participant is allowed.
# Multiple ranked submissions from the same participant will not be judged.
# Non-ranked submissions are accepted so we can verify that they were made before the deadline.
# The "Ranked:" keyword is required, and expects a Boolean value (True/False)
Ranked:
True


# METHOD DESCRIPTION SECTION
#
# Methodology and computational details.
# Level of detail should be at least that used in a publication.
# Please include the values of key parameters, with units, and explain how any
# statistical uncertainties were estimated.
# Use as many lines of text as you need.
# Please explicitly describe how you handle ions (e.g. counterions) and pKa effects
# Following is sample text; please edit to your taste.
# All text following the "Method:" keyword will be regarded as part of your free text methods description.
Method:
A subset of provided compounds (explain how selected/from which set) were docked into the PHIP2 binding site
using (describe which) docking software and sorted by score. The most promising compounds were then subjected
to short MD simulations with OpenMM using the AMBER (explain which) protein force field and the OpenFF 1.0 small molecule force field
with additional details provided in (link to simulation setup script). Following simulation, we looked at compound RMSD in the binding site
and retained those compounds with low RMSD (< X angstroms) relative to their starting binding mode and low RMS fluctuations.
These binding modes were then manually inspected for stability and sensible contacts, and compared with known binding modes
of fragments from Stage 3. Based on this, we retained N of the M resulting low RMSD compounds.

Our final list of N compounds contains the following compounds and binding modes, which we rationalize as follows:
(Provide a list of the compounds selected and why they were selected).
